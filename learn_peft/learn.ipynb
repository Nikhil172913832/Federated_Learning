{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67879af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "import open_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916b57a-99fd-40c2-aa5a-792a47134761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_byte_array(byte_array):\n",
    "    return Image.open(io.BytesIO(byte_array))\n",
    "dataset = load_dataset(\"ykumards/open-i\")\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "dataset = dataset.filter(lambda example: example['img_frontal'] is not None)\n",
    "dataset = dataset.filter(lambda example: example['impression'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc75be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    'hf-hub:luhuitong/CLIP-ViT-L-14-448px-MedICaT-ROCO'\n",
    ")\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:luhuitong/CLIP-ViT-L-14-448px-MedICaT-ROCO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all model parameters with their shapes and count total parameters\n",
    "total_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:60} {str(tuple(param.shape)):25} trainable={param.requires_grad}\")\n",
    "    total_params += param.numel()\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all modules with their names, types, and parameter counts\n",
    "for name, module in model.named_modules():\n",
    "    num_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    print(f\"{name:60} {type(module).__name__:30} trainable_params={num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Show a torchinfo summary if available\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    summary(model, depth=4, col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"] )\n",
    "except ImportError:\n",
    "    print(\"Install torchinfo with: pip install torchinfo for a compact summary view.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d249eb-afc7-47d5-b004-3b32f782de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "peft_config = LoraConfig(\n",
    "    r=16,                      # rank\n",
    "    lora_alpha=32,             # scaling\n",
    "    target_modules = [\n",
    "    f\"visual.transformer.resblocks.{i}.attn.q_proj\" for i in range(23, 24)\n",
    "] + [\n",
    "    f\"visual.transformer.resblocks.{i}.attn.k_proj\" for i in range(23, 24)\n",
    "] + [\n",
    "    f\"visual.transformer.resblocks.{i}.attn.v_proj\" for i in range(23, 24)\n",
    "] + [\n",
    "    f\"visual.transformer.resblocks.{i}.attn.out_proj\" for i in range(23, 24)\n",
    "],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"FEATURE_EXTRACTION\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f35917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/home/darklord/Projects/Federated_Learning/models\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ca177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    pixel_values = []\n",
    "    for img_bytes in batch['img_frontal']:\n",
    "        img = load_image_from_byte_array(img_bytes)\n",
    "        tensor = preprocess(img)\n",
    "        pixel_values.append(tensor)\n",
    "    batch['pixel_values'] = pixel_values\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffdb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(preprocess_batch, batched=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(batch):\n",
    "    tokens = tokenizer(batch['impression'])\n",
    "    batch['input_ids'] = tokens['input_ids']\n",
    "    batch['attention_mask'] = tokens['attention_mask']\n",
    "    return batch\n",
    "\n",
    "\n",
    "dataset = dataset.map(tokenize_batch, batched=True, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer(dataset[\"train\"][0])\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
